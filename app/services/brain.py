"""
Servi√ßo de Intelig√™ncia Artificial H√≠brido.
Ouvido: Groq (Whisper) - R√°pido e Gratuito.
C√©rebro: OpenRouter (DeepSeek/Llama) - Inteligente.
"""
import pathlib
import os
from openai import AsyncOpenAI
from app.config import settings
from app.utils.logger import setup_logger

logger = setup_logger(__name__)

class BrainService:
    """
    Gerenciador de racioc√≠nio e audi√ß√£o.
    """

    # Prompt de Vendas
    SYSTEM_PROMPT = """
    Voc√™ √© o Alex, um SDR s√™nior e consultor da 'TechSolutions'.
    
    Objetivo: 
    Conversar naturalmente com o lead para entender suas necessidades e, se fizer sentido, agendar uma reuni√£o.
    
    Diretrizes de Personalidade:
    1. Responda de forma fluida e humana (varie o vocabul√°rio, evite repetir v√≠cios de linguagem como 't√° bom' em toda frase).
    2. Seja conciso, mas entregue valor (respostas ideais entre 1 a 3 frases).
    3. Use tom profissional mas acolhedor.
    4. NUNCA use emojis.
    5. Sempre mantenha a conversa viva com uma pergunta relevante no final.
    """

    def __init__(self):
        # 1. Configura o C√âREBRO (Texto -> Texto)
        # Usa as configura√ß√µes do config.py (OpenRouter/DeepSeek)
        try:
            self.client_brain = AsyncOpenAI(
                api_key=settings.openai_api_key,
                base_url=settings.openai_base_url
            )
            self.model_brain = settings.openai_model
            logger.info(f"üß† C√©rebro conectado: {self.model_brain}")
        except Exception as e:
            logger.critical(f"Falha ao iniciar C√©rebro: {e}")
            raise

        # 2. Configura o OUVIDO (√Åudio -> Texto)
        # Usa a Groq Cloud (Whisper-large-v3) que √© extremamente r√°pida
        self.groq_api_key = os.getenv("GROQ_API_KEY")
        
        if self.groq_api_key:
            self.client_ear = AsyncOpenAI(
                api_key=self.groq_api_key,
                base_url="https://api.groq.com/openai/v1"
            )
            logger.info("üëÇ Ouvido ativado: Whisper via Groq.")
        else:
            self.client_ear = None
            logger.warning("‚ö†Ô∏è Chave GROQ_API_KEY n√£o encontrada no .env. O bot continuar√° 'fingindo' que ouviu.")

    async def transcribe_audio(self, audio_path: str) -> str:
        """
        Transcreve o √°udio usando Groq Whisper (Real) ou Fallback (Simulado).
        """
        # Modo Simula√ß√£o (se n√£o tiver chave)
        if not self.client_ear:
            logger.warning("Simulando audi√ß√£o (Adicione GROQ_API_KEY no .env para corrigir)")
            return "Ol√°, vi seu an√∫ncio no Instagram e quero saber mais."

        # Modo Real (Groq)
        try:
            path_obj = pathlib.Path(audio_path)
            if not path_obj.exists():
                logger.error(f"Arquivo de √°udio n√£o existe: {audio_path}")
                return ""

            # Abre o arquivo e envia para a Groq
            with open(path_obj, "rb") as audio_file:
                transcription = await self.client_ear.audio.transcriptions.create(
                    file=audio_file,
                    model="whisper-large-v3", # Melhor modelo open-source atual
                    response_format="text",
                    language="pt" # For√ßa portugu√™s para evitar alucina√ß√µes
                )
            
            text_result = str(transcription).strip()
            logger.info(f"üó£Ô∏è Transcri√ß√£o Real: {text_result}")
            return text_result

        except Exception as e:
            logger.error(f"‚ùå Erro na transcri√ß√£o (Groq): {e}")
            return ""

    # from app.services.evolution import evolution_service

    async def process_audio_and_respond(self, audio_path: str | pathlib.Path, remote_jid: str) -> str:
        """
        Pipeline: Ouvir (Groq) -> Lembrar (Evolution) -> Pensar (DeepSeek)
        """
        try:
            # 1. Ouvir (Transcri√ß√£o)
            user_text = await self.transcribe_audio(str(audio_path))
            
            if not user_text or len(user_text) < 2: 
                return "Oi, n√£o consegui te ouvir direito. Pode mandar de novo?"

            # 2. Lembrar (Busca hist√≥rico na Evolution)
            # Importa√ß√£o local para evitar ciclo de importa√ß√£o circular, se necess√°rio
            from app.services.evolution import evolution_service 
            
            history_data = await evolution_service.get_history(remote_jid, limit=5)
            
            # Formata hist√≥rico para o padr√£o OpenAI
            messages_context = [{"role": "system", "content": self.SYSTEM_PROMPT}]
            
            for msg in history_data:
                # Filtra apenas texto/conversas v√°lidas
                content = msg.get("message", {}).get("conversation") or \
                          msg.get("message", {}).get("extendedTextMessage", {}).get("text")
                
                if content:
                    role = "assistant" if msg["key"]["fromMe"] else "user"
                    messages_context.append({"role": role, "content": content})

            # Adiciona a mensagem atual do usu√°rio
            messages_context.append({"role": "user", "content": user_text})

            # 3. Pensar (Envia tudo para a IA)
            response = await self.client_brain.chat.completions.create(
                model=self.model_brain,
                messages=messages_context, # Agora com hist√≥rico!
                temperature=0.6,
                max_tokens=150
            )

            reply = response.choices[0].message.content
            clean_reply = reply.strip().replace('"', '').replace("*", "")
            
            logger.info(f"üß† C√©rebro Respondeu (com contexto): {clean_reply}")
            return clean_reply

        except Exception as e:
            logger.error(f"‚ùå Erro no c√©rebro: {e}", exc_info=True)
            return "Oi! Tive um problema t√©cnico. Pode repetir o √°udio?"

# Singleton
brain_service = BrainService()