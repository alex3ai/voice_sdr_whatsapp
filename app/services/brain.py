"""
Servi√ßo de Intelig√™ncia Artificial usando Google Gemini.
Implementa√ß√£o 100% Ass√≠ncrona com Fallback e Leitura n√£o-bloqueante.
"""
import aiofiles
import pathlib
from typing import Optional

from google import genai
from google.api_core import exceptions as google_exceptions
from google.genai import types

from app.config import settings
from app.utils.exceptions import GeminiApiException
from app.utils.logger import logger


class BrainService:
    """
    Gerenciador de racioc√≠nio (IA) com estrat√©gia de redund√¢ncia.
    """

    # Prompt do sistema: Define a personalidade do SDR
    SYSTEM_PROMPT = """
Voc√™ √© o 'Alex', um consultor de vendas experiente da 'TechSolutions Brasil'.

**Sua miss√£o:**
- Ouvir a d√∫vida do cliente no √°udio.
- Responder de forma clara, curta (m√°x 3 frases) e persuasiva.
- Focar em qualificar o lead para uma demonstra√ß√£o.

**Regras:**
1. Linguagem natural de WhatsApp (coloquial, educada, sem g√≠rias pesadas).
2. NUNCA use formata√ß√£o markdown (negrito, it√°lico) - isso quebra o TTS.
3. Se o √°udio for inaud√≠vel, pe√ßa educadamente para repetir.
4. Se o cliente perguntar pre√ßo, diga que depende do perfil e sugira uma call r√°pida.
"""

    def __init__(self):
        try:
            # Inicializa o cliente do Google GenAI
            self.client = genai.Client(api_key=settings.gemini_api_key)

            # Estrat√©gia de Modelos (Primary -> Fallback)
            self.primary_model = settings.gemini_model_primary
            self.fallback_model = settings.gemini_model_fallback
            self._current_model = self.primary_model

            logger.info(
                f"üß† Brain inicializado. Modelo Principal: {self._current_model}"
            )
        except Exception as e:
            logger.critical(f"Falha cr√≠tica ao iniciar BrainService: {e}")
            raise

    async def process_audio_and_respond(
        self, audio_path: pathlib.Path | str
    ) -> str:
        """
        L√™ o arquivo de √°udio e solicita resposta √† IA.
        """
        path_obj = pathlib.Path(audio_path)

        if not path_obj.exists():
            logger.error(f"Arquivo de √°udio n√£o encontrado: {audio_path}")
            # Retornar uma mensagem padr√£o para o usu√°rio final
            return "Ops, n√£o encontrei o arquivo de √°udio que voc√™ enviou."

        try:
            # 1. Leitura n√£o-bloqueante do disco (usando aiofiles)
            async with aiofiles.open(path_obj, "rb") as f:
                audio_bytes = await f.read()

            file_size_kb = len(audio_bytes) / 1024

            # Valida√ß√£o simples para economizar API
            if len(audio_bytes) < 100:
                logger.warning("√Åudio vazio ou muito curto ignorado.")
                return "N√£o consegui te ouvir, o √°udio ficou mudo. Pode repetir?"

            logger.info(f"Enviando {file_size_kb:.1f}KB para o Gemini...")

            # 2. Tenta modelo prim√°rio com l√≥gica de fallback interna
            response = await self._try_models_with_fallback(audio_bytes)

            return response

        except GeminiApiException as e:
            # Erro j√° logado na camada da API, aqui apenas tratamos o fluxo
            logger.error(f"Falha na comunica√ß√£o com a API do Gemini: {e}")
            return self._get_fallback_message()
        except Exception as e:
            logger.error(f"Erro inesperado no pipeline do Brain: {e}", exc_info=True)
            return self._get_fallback_message()

    async def _try_models_with_fallback(self, audio_bytes: bytes) -> str:
        """Tenta o modelo prim√°rio e, em caso de falha, aciona o fallback."""
        try:
            # Tenta o modelo atual (que pode ser prim√°rio ou fallback)
            return await self._call_gemini_api(audio_bytes, self._current_model)
        except GeminiApiException as e:
            logger.warning(
                f"Modelo {self._current_model} falhou. Tentando fallback para {self.fallback_model}..."
            )
            # Se o modelo atual (prim√°rio) falhou, tenta o fallback
            if self._current_model == self.primary_model:
                try:
                    response = await self._call_gemini_api(
                        audio_bytes, self.fallback_model
                    )
                    # Se o fallback funcionar, define-o como o modelo atual
                    self._current_model = self.fallback_model
                    logger.info(
                        f"Sucesso com o fallback. Novo modelo padr√£o: {self.fallback_model}"
                    )
                    return response
                except GeminiApiException as fallback_e:
                    logger.critical(
                        f"Modelo de fallback ({self.fallback_model}) tamb√©m falhou. {fallback_e}"
                    )
                    raise fallback_e  # Relan√ßa a exce√ß√£o do fallback
            # Se o modelo que falhou j√° era o fallback, apenas relan√ßa a exce√ß√£o
            raise e

    async def _call_gemini_api(
        self, audio_bytes: bytes, model: str
    ) -> str:
        """
        Realiza a chamada √† API do Google e encapsula os erros.
        Lan√ßa GeminiApiException em caso de falha.
        """
        try:
            response = await self.client.aio.models.generate_content(
                model=model,
                contents=[
                    types.Content(
                        role="user",
                        parts=[
                            types.Part.from_text(text="Responda a este √°udio como Alex."),
                            types.Part.from_bytes(
                                data=audio_bytes, mime_type="audio/ogg"
                            ),
                        ],
                    )
                ],
                config=types.GenerateContentConfig(
                    system_instruction=self.SYSTEM_PROMPT,
                    temperature=0.7,
                    max_output_tokens=200,  # Mant√©m resposta curta
                ),
            )

            if response and response.text:
                clean_text = response.text.strip()
                logger.info(f"ü§ñ Resposta gerada ({len(clean_text)} chars)")
                return clean_text

            # Se a resposta for vazia mas n√£o houve exce√ß√£o
            raise GeminiApiException("A API do Gemini retornou uma resposta vazia.")

        except (
            google_exceptions.GoogleAPICallError,
            google_exceptions.RetryError,
            Exception,
        ) as e:
            error_message = f"Erro na chamada √† API Gemini ({model})"
            logger.error(f"{error_message}: {e}")
            raise GeminiApiException(error_message, original_exception=e)

    @staticmethod
    def _get_fallback_message() -> str:
        """Mensagem segura quando a IA est√° indispon√≠vel."""
        return "Tive um problema t√©cnico para processar seu √°udio. Voc√™ poderia, por favor, tentar novamente ou escrever sua mensagem?"


# Singleton
brain_service = BrainService()